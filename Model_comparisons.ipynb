{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multimodal_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyR6Wx+11lPdU4arYEiNBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaneelgit/msi_voxceleb/blob/main/Model_comparisons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvnvL5rfm9HY"
      },
      "source": [
        "<font size = '6'> <center>**Model Comparison**</center></font>\n",
        "\n",
        "Here I am combining the two models based on bayesian cue combination. I use the trained video and audio models and will be combining them based on the precision of each data source. Here I will be assuming that both audio and video data are 100% precise for simplicity. Then I will be compairing the three model performances in the end. \n",
        "\n",
        "VoxCeleb dataset - https://www.robots.ox.ac.uk/~vgg/data/voxceleb/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hUyLehvmr4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee15f110-944b-4e4c-fae6-6fcfbebcf2cb"
      },
      "source": [
        "#import libraries\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2     # for capturing videos\n",
        "import math\n",
        "import random\n",
        "\n",
        "import moviepy.editor as mp\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2260992/45929032 bytes (4.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5480448/45929032 bytes (11.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8486912/45929032 bytes (18.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11870208/45929032 bytes (25.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15425536/45929032 bytes (33.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18841600/45929032 bytes (41.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22339584/45929032 bytes (48.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25632768/45929032 bytes (55.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28614656/45929032 bytes (62.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31907840/45929032 bytes (69.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35160064/45929032 bytes (76.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38363136/45929032 bytes (83.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41623552/45929032 bytes (90.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44924928/45929032 bytes (97.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAYmTkGOoAmR"
      },
      "source": [
        "# **Download and unzip the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQI9vcEWoEUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8aa37fa-994f-47ce-e489-8b91c50ef8de"
      },
      "source": [
        "#get url\n",
        "!wget \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_mp4.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 13:32:08--  https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_mp4.zip\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8906971319 (8.3G) [application/zip]\n",
            "Saving to: ‘vox2_test_mp4.zip’\n",
            "\n",
            "vox2_test_mp4.zip   100%[===================>]   8.29G  11.8MB/s    in 12m 36s \n",
            "\n",
            "2021-10-31 13:44:45 (11.2 MB/s) - ‘vox2_test_mp4.zip’ saved [8906971319/8906971319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOF5ENJXocup"
      },
      "source": [
        "!unzip vox2_test_mp4.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG7Ew3wIohXL"
      },
      "source": [
        "# **Organizing the data**\n",
        "\n",
        "In the cells below I am collecting all the video paths in a list. I will be then using these videos to extract the audios and their spectrograms to feed in to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWY6HS5qolDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f622a4d-fcd8-48d0-d712-304d2f59247d"
      },
      "source": [
        "#get video paths\n",
        "vid_paths = []\n",
        "\n",
        "for path, directories, files in os.walk('/content/mp4/'):\n",
        "\n",
        "  for file in files:\n",
        "\n",
        "    vid_paths.append(str(path) + '/' + str(file))\n",
        "\n",
        "#number of videos available\n",
        "print('Number of videos available: ', len(vid_paths))\n",
        "\n",
        "#shuffle video paths. I have used a random seed of 4 to shuffle.\n",
        "random.seed(10)\n",
        "random.shuffle(vid_paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos available:  36237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv9uwkDDo3M2"
      },
      "source": [
        "# **Upload the CSV file and clean meta data**\n",
        "\n",
        "\n",
        "The csv file with meta data is in my github repository. (https://github.com/kaneelgit/msi_voxceleb). You have to upload the csv file to colab before running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG7zdCMeo7M7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d7f5bd8f-3b6f-49ea-8e53-597b687ff527"
      },
      "source": [
        "#some functions to clean the csv file\n",
        "#del spaces from the ids and gender\n",
        "def del_spaces(string):\n",
        "  \n",
        "  string = string.replace(' ', '')\n",
        "\n",
        "  return string\n",
        "\n",
        "#upload csv file from github before running\n",
        "#open csv file\n",
        "df = pd.read_csv('/content/vox2_meta.csv')\n",
        "df.head(5)\n",
        "\n",
        "#clean the dataset\n",
        "\n",
        "#apply the function to get rid of spaces\n",
        "df['VoxCeleb2 ID'] = df['VoxCeleb2 ID'].apply(del_spaces)\n",
        "df['VGGFace2 ID'] = df['VGGFace2 ID'].apply(del_spaces)\n",
        "df['Gender'] = df['Gender'].apply(del_spaces)\n",
        "df['Set'] = df['Set'].apply(del_spaces)\n",
        "\n",
        "\n",
        "#get the test data\n",
        "df2 = df[df['Set'] == 'test']\n",
        "df2['Gender'] = df2['Gender'].astype('category')\n",
        "\n",
        "df2.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VoxCeleb2 ID</th>\n",
              "      <th>VGGFace2 ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id00017</td>\n",
              "      <td>n000017</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>id00061</td>\n",
              "      <td>n000061</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>id00081</td>\n",
              "      <td>n000081</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>id00154</td>\n",
              "      <td>n000154</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>id00419</td>\n",
              "      <td>n000419</td>\n",
              "      <td>f</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    VoxCeleb2 ID VGGFace2 ID Gender   Set\n",
              "3        id00017     n000017      m  test\n",
              "36       id00061     n000061      m  test\n",
              "53       id00081     n000081      m  test\n",
              "89       id00154     n000154      m  test\n",
              "271      id00419     n000419      f  test"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XRcch4RpFwr"
      },
      "source": [
        "# **Create a Labels List**\n",
        "\n",
        "Here I am going through the ids of all the video files and picking the gender from the CSV file. Note that there are double the size of male videos compared to female. So I will be taking every other video file to balance the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xfWWVIhpMmF"
      },
      "source": [
        "#iterate through the vid_paths get the id of the person and get if the person is female or male. If the person is male its a 1 and female its a 0\n",
        "labels = []\n",
        "\n",
        "#get only half of the male videos.\n",
        "count = 0\n",
        "video_files = []\n",
        "\n",
        "#iterate\n",
        "for path in vid_paths:\n",
        "  \n",
        "  #get id number\n",
        "  id_str =  path[13:20]\n",
        "\n",
        "  #get if the subject is male or female from the csv\n",
        "  gender = df2.loc[df2['VoxCeleb2 ID'] == str(id_str)]['Gender'].values[0]\n",
        "\n",
        "  if gender == 'm':\n",
        "    if count % 2 == 0:\n",
        "      labels.append(1)\n",
        "      video_files.append(path)\n",
        "    count += 1\n",
        "  \n",
        "  else:\n",
        "    labels.append(0)\n",
        "    video_files.append(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6npGYWgwKjM"
      },
      "source": [
        "def convert_data(path):\n",
        "\n",
        "  #get label\n",
        "  id_str =  path[13:20]\n",
        "\n",
        "  #get if the subject is male or female from the csv\n",
        "  gender = df2.loc[df2['VoxCeleb2 ID'] == str(id_str)]['Gender'].values[0]\n",
        "\n",
        "  label = 1 if gender == 'm' else 0\n",
        "\n",
        "  #video processing\n",
        "  video = mp.VideoFileClip(path).subclip(0, 3)\n",
        "\n",
        "  #imag\n",
        "  imag = video.get_frame(0)/255\n",
        "\n",
        "  #audio processing\n",
        "  audio = video.audio.to_soundarray()\n",
        "\n",
        "  #sampling rate\n",
        "  fs = 44100\n",
        "  \n",
        "  #channel 1\n",
        "  ch1 = librosa.feature.melspectrogram(audio[:, 0], sr = fs)\n",
        "  mel_ch1 = librosa.amplitude_to_db(ch1, ref = np.min)\n",
        "\n",
        "  return imag, mel_ch1.reshape(mel_ch1.shape[0], mel_ch1.shape[1], 1), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D3f6wPvpv6a"
      },
      "source": [
        "# **Compairing Models**\n",
        "\n",
        "First I will recreate the audio and video model architectures since I only saved the weights of each model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeoq7LF33gxZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Average, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNMxNShcw_ri"
      },
      "source": [
        "#Audio Model\n",
        "def aud_model(x):\n",
        "    \n",
        "    inputs = x\n",
        "    x = tf.keras.layers.Conv2D(16, kernel_size = (3, 3),activation = 'relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu')(x) \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "#input\n",
        "input_samp = np.zeros([16, 128, 259, 1])\n",
        "\n",
        "#input\n",
        "input = Input(input_samp[0, :].shape, name = 'audio')\n",
        "out = aud_model(input)\n",
        "out = Flatten()(out)\n",
        "out = Dropout(0.5)(out)\n",
        "out = Dense(1024, activation = 'relu')(out)\n",
        "out = Dropout(0.8)(out)\n",
        "out = Dense(128, activation = 'relu')(out)\n",
        "output = Dense(1, activation = 'sigmoid', name = 'class')(out)\n",
        "\n",
        "#create the model\n",
        "audio_model = Model(input, output)\n",
        "audio_model.load_weights('audition.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAu3P3wAc6fi"
      },
      "source": [
        "#Video Model\n",
        "def vid_model(x):\n",
        "    \n",
        "    inputs = x\n",
        "    x = tf.keras.layers.Conv2D(16, kernel_size = (3, 3),activation = 'relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size = (6, 6), activation = 'relu')(x) \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#input\n",
        "input_samp = np.zeros([16, 224, 224, 3])\n",
        "\n",
        "#input\n",
        "input = Input(input_samp[0, :].shape, name = 'video')\n",
        "out = vid_model(input)\n",
        "out = Flatten()(out)\n",
        "out = Dropout(0.5)(out)\n",
        "out = Dense(1024, activation = 'relu')(out)\n",
        "out = Dense(128, activation = 'relu')(out)\n",
        "output = Dense(1, activation = 'sigmoid', name = 'class')(out)\n",
        "\n",
        "#create the model\n",
        "video_model = Model(input, output)\n",
        "video_model.load_weights('vision.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DucKIrtS83JG"
      },
      "source": [
        "## **Functions that predict if male or female given data**\n",
        "\n",
        "Here I am creating three functions (audio, video and bimodal) that predicts if the given data is of a female or a male. \n",
        "\n",
        "For the bimodal prediction, I will be using the bayesian cue combination model. I will be weighting the video and audio data by it's precision. The default precision value is set to 1. In this case I will be using precisions for both video and audio data to be 1. In other words I am assuming that data by both sources are 100% precise. So the bimodal prediction in this case will be just the average of the video and audio prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9knIGvhfn07u"
      },
      "source": [
        "#create audio only video only and multimodel prediction functions\n",
        "def aud_pred(aud_array):\n",
        "  #reshape the audio array\n",
        "  aud_array = aud_array.reshape(1, aud_array.shape[0], aud_array.shape[1], aud_array.shape[2])\n",
        "  #calculate the prediction\n",
        "  pred = audio_model.predict(aud_array)[0][0]\n",
        "\n",
        "  return 1 if pred >= 0.5 else 0\n",
        "\n",
        "def vid_pred(vid_array):\n",
        "  #reshape the video array\n",
        "  vid_array = vid_array.reshape(1, vid_array.shape[0], vid_array.shape[1], vid_array.shape[2])\n",
        "  #calculate the prediction\n",
        "  pred = video_model.predict(vid_array)[0][0]\n",
        "\n",
        "  return 1 if pred >= 0.5 else 0\n",
        "\n",
        "def bimod_pred(vid_array, aud_array, vid_prec = 1, aud_prec = 1):\n",
        "  #reshape arrays\n",
        "  aud_array = aud_array.reshape(1, aud_array.shape[0], aud_array.shape[1], aud_array.shape[2])\n",
        "  vid_array = vid_array.reshape(1, vid_array.shape[0], vid_array.shape[1], vid_array.shape[2])\n",
        "\n",
        "  #predictions\n",
        "  aud_pred = audio_model.predict(aud_array)[0][0]\n",
        "\n",
        "  #video prediction\n",
        "  vid_pred = video_model.predict(vid_array)[0][0]\n",
        "\n",
        "  #calculate bimodal outcome\n",
        "  bimod_pred = vid_prec/(aud_prec + vid_prec) * vid_pred + aud_prec/(aud_prec + vid_prec) * aud_pred\n",
        "\n",
        "  return 1 if bimod_pred >= 0.5 else 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO4k0tW2-L9-"
      },
      "source": [
        "## **Calculate accuracies of the three Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MOpcI9Ds3yx"
      },
      "source": [
        "#get data\n",
        "random_idx = np.random.choice(np.arange(0, len(video_files)), 1000)\n",
        "\n",
        "#Convert these to 10 batches\n",
        "batches = [random_idx[i : i + 100] for i in range(0, len(random_idx), 100)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvebST9iteIr"
      },
      "source": [
        "#calculate the accuracies\n",
        "vid_acc = []\n",
        "aud_acc = []\n",
        "bimod_acc = []\n",
        "\n",
        "for batch in batches:\n",
        "  #arrays for each batch data \n",
        "  vid = []\n",
        "  aud = []\n",
        "  bimod = []\n",
        "\n",
        "  for idx in batch:\n",
        "    \n",
        "    #get path\n",
        "    path = video_files[idx]\n",
        "\n",
        "    #get image, audio and label\n",
        "    img, audio, label = convert_data(path)\n",
        "    \n",
        "    #make predictions\n",
        "    vid_prediction = vid_pred(img)\n",
        "    aud_prediction = aud_pred(audio)\n",
        "    bimod_prediction = bimod_pred(img, audio)\n",
        "\n",
        "    #collect data\n",
        "    vid.append(1 if vid_prediction == label else 0)\n",
        "    aud.append(1 if aud_prediction == label else 0)\n",
        "    bimod.append(1 if bimod_prediction == label else 0)\n",
        "\n",
        "  #calculate the accuracies\n",
        "  video_batch_acc = np.sum(vid)/len(vid)\n",
        "  audio_batch_acc = np.sum(aud)/len(aud)\n",
        "  bimod_batch_acc = np.sum(bimod)/len(bimod)\n",
        "\n",
        "  #append data\n",
        "  vid_acc.append(video_batch_acc)\n",
        "  aud_acc.append(audio_batch_acc)\n",
        "  bimod_acc.append(bimod_batch_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2pzeIsy-c_H"
      },
      "source": [
        "# **Plotting results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPM4vQt6t8CK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "f415dec4-004e-45c3-c518-e5a0935c84f5"
      },
      "source": [
        "#bar plot with accuracies\n",
        "#means\n",
        "video_mean = np.mean(vid_acc)\n",
        "audio_mean = np.mean(aud_acc)\n",
        "bimod_mean = np.mean(bimod_acc)\n",
        "\n",
        "#std\n",
        "video_std = np.std(vid_acc)\n",
        "audio_std = np.std(aud_acc)\n",
        "bimod_std = np.std(bimod_acc)\n",
        "\n",
        "#data\n",
        "models = ['Video', 'Audio', 'Bimodal']\n",
        "x_pos = np.arange(len(models))\n",
        "mod_means = [video_mean, audio_mean, bimod_mean]\n",
        "mod_errors = [video_std, audio_std, bimod_std]\n",
        "\n",
        "#figure\n",
        "fig, ax = plt.subplots(figsize = (8, 5))\n",
        "ax.bar(x_pos, mod_means, yerr = mod_errors, align = 'center', alpha = 0.5, ecolor = 'black', capsize = 10)\n",
        "ax.scatter(np.zeros(len(vid_acc))- 0.2, vid_acc)\n",
        "ax.scatter(np.ones(len(aud_acc))- 0.2, aud_acc)\n",
        "ax.scatter(np.ones(len(bimod_acc))*2 - 0.2, bimod_acc)\n",
        "ax.set_ylabel('Model Accuracies', fontsize =  13)\n",
        "ax.set_ylim([0.7, 1])\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(models, fontsize = 13)\n",
        "ax.set_title('Performance of each model', fontsize = 18)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maAyUPE-60Nh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}