{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multimodal_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4Qyh5bsh4PTBy9yCw6rjk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaneelgit/msi_voxceleb/blob/main/Model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvnvL5rfm9HY"
      },
      "source": [
        "<font size = '6'> <center>**Model Comparison**</center></font>\n",
        "\n",
        "Here I am using a multimodal approach. I will be using both video and audio data for gender classification. The videos feature extraction will be done by a 3D CNN model as before and the audio classification will be done by a 2D classification model as before. \n",
        "\n",
        "VoxCeleb dataset - https://www.robots.ox.ac.uk/~vgg/data/voxceleb/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hUyLehvmr4m"
      },
      "source": [
        "#import libraries\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2     # for capturing videos\n",
        "import math\n",
        "import random\n",
        "\n",
        "import moviepy.editor as mp\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAYmTkGOoAmR"
      },
      "source": [
        "# **Download and unzip the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQI9vcEWoEUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4441fd-2bdd-4b16-f0e2-7e8a945ee84c"
      },
      "source": [
        "#get url\n",
        "!wget \"https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_mp4.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-30 23:38:48--  https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_test_mp4.zip\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8906971319 (8.3G) [application/zip]\n",
            "Saving to: ‘vox2_test_mp4.zip’\n",
            "\n",
            "vox2_test_mp4.zip   100%[===================>]   8.29G  35.1MB/s    in 4m 6s   \n",
            "\n",
            "2021-10-30 23:42:55 (34.5 MB/s) - ‘vox2_test_mp4.zip’ saved [8906971319/8906971319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOF5ENJXocup"
      },
      "source": [
        "!unzip vox2_test_mp4.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG7Ew3wIohXL"
      },
      "source": [
        "# **Organizing the data**\n",
        "\n",
        "In the cells below I am collecting all the video paths in a list. I will be then using these videos to extract the audios and their spectrograms to feed in to the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWY6HS5qolDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e421846-6344-48e4-84af-6f4d15220b76"
      },
      "source": [
        "#get video paths\n",
        "vid_paths = []\n",
        "\n",
        "for path, directories, files in os.walk('/content/mp4/'):\n",
        "\n",
        "  for file in files:\n",
        "\n",
        "    vid_paths.append(str(path) + '/' + str(file))\n",
        "\n",
        "#number of videos available\n",
        "print('Number of videos available: ', len(vid_paths))\n",
        "\n",
        "#shuffle video paths. I have used a random seed of 4 to shuffle.\n",
        "random.seed(4)\n",
        "random.shuffle(vid_paths)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos available:  36237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv9uwkDDo3M2"
      },
      "source": [
        "# **Upload the CSV file and clean meta data**\n",
        "\n",
        "\n",
        "The csv file with meta data is in my github repository. (https://github.com/kaneelgit/msi_voxceleb). You have to upload the csv file to colab before running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG7zdCMeo7M7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "80d1720f-4618-40f0-e466-499bb25d3514"
      },
      "source": [
        "#some functions to clean the csv file\n",
        "#del spaces from the ids and gender\n",
        "def del_spaces(string):\n",
        "  \n",
        "  string = string.replace(' ', '')\n",
        "\n",
        "  return string\n",
        "\n",
        "#upload csv file from github before running\n",
        "#open csv file\n",
        "df = pd.read_csv('/content/vox2_meta.csv')\n",
        "df.head(5)\n",
        "\n",
        "#clean the dataset\n",
        "\n",
        "#apply the function to get rid of spaces\n",
        "df['VoxCeleb2 ID'] = df['VoxCeleb2 ID'].apply(del_spaces)\n",
        "df['VGGFace2 ID'] = df['VGGFace2 ID'].apply(del_spaces)\n",
        "df['Gender'] = df['Gender'].apply(del_spaces)\n",
        "df['Set'] = df['Set'].apply(del_spaces)\n",
        "\n",
        "\n",
        "#get the test data\n",
        "df2 = df[df['Set'] == 'test']\n",
        "df2['Gender'] = df2['Gender'].astype('category')\n",
        "\n",
        "df2.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VoxCeleb2 ID</th>\n",
              "      <th>VGGFace2 ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id00017</td>\n",
              "      <td>n000017</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>id00061</td>\n",
              "      <td>n000061</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>id00081</td>\n",
              "      <td>n000081</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>id00154</td>\n",
              "      <td>n000154</td>\n",
              "      <td>m</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>id00419</td>\n",
              "      <td>n000419</td>\n",
              "      <td>f</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    VoxCeleb2 ID VGGFace2 ID Gender   Set\n",
              "3        id00017     n000017      m  test\n",
              "36       id00061     n000061      m  test\n",
              "53       id00081     n000081      m  test\n",
              "89       id00154     n000154      m  test\n",
              "271      id00419     n000419      f  test"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XRcch4RpFwr"
      },
      "source": [
        "# **Create a Labels List**\n",
        "\n",
        "Here I am going through the ids of all the video files and picking the gender from the CSV file. Note that there are double the size of male videos compared to female. So I will be taking every other video file to balance the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xfWWVIhpMmF"
      },
      "source": [
        "#iterate through the vid_paths get the id of the person and get if the person is female or male. If the person is male its a 1 and female its a 0\n",
        "labels = []\n",
        "\n",
        "#get only half of the male videos.\n",
        "count = 0\n",
        "video_files = []\n",
        "\n",
        "#iterate\n",
        "for path in vid_paths:\n",
        "  \n",
        "  #get id number\n",
        "  id_str =  path[13:20]\n",
        "\n",
        "  #get if the subject is male or female from the csv\n",
        "  gender = df2.loc[df2['VoxCeleb2 ID'] == str(id_str)]['Gender'].values[0]\n",
        "\n",
        "  if gender == 'm':\n",
        "    if count % 2 == 0:\n",
        "      labels.append(1)\n",
        "      video_files.append(path)\n",
        "    count += 1\n",
        "  \n",
        "  else:\n",
        "    labels.append(0)\n",
        "    video_files.append(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6npGYWgwKjM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D3f6wPvpv6a"
      },
      "source": [
        "# **Compairing Models**\n",
        "\n",
        "Here I am creating a data generator to feed audio and video data to the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeoq7LF33gxZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Average, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNMxNShcw_ri"
      },
      "source": [
        "#CNN MODEL\n",
        "def cnn_model(x):\n",
        "    \n",
        "    inputs = x\n",
        "    x = tf.keras.layers.Conv2D(16, kernel_size = (3, 3),activation = 'relu')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu')(x) \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size = (2, 2))(x)\n",
        "    \n",
        "    # x = tf.keras.layers.Conv3D(64, kernel_size = (3, 3, 1), activation = 'relu')(x) \n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.MaxPool3D(pool_size = (2, 2, 1))(x)\n",
        "   \n",
        "    return x\n",
        "\n",
        "#input\n",
        "input_samp = np.zeros([16, 128, 259, 1])\n",
        "\n",
        "#input\n",
        "input = Input(input_samp[0, :].shape, name = 'audio')\n",
        "out = cnn_model(input)\n",
        "out = Flatten()(out)\n",
        "out = Dropout(0.5)(out)\n",
        "out = Dense(1024, activation = 'relu')(out)\n",
        "out = Dropout(0.8)(out)\n",
        "out = Dense(128, activation = 'relu')(out)\n",
        "output = Dense(1, activation = 'sigmoid', name = 'class')(out)\n",
        "\n",
        "#create the model\n",
        "audio_cnn_model = Model(input, output)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZTdAQ2u1Kzz"
      },
      "source": [
        "audio_cnn_model.load_weights('audition.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waU9yihh1de9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}